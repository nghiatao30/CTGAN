{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3325ffc8-9aff-4507-a765-1601c0f0b6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed094f0f-8b75-444e-929d-702172541ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5914ec7d-57d2-43d6-959e-34df7b9a3f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298d946a-6489-4005-b822-661ab3259e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "data1 = pd.read_csv('data20sp\\ctgandim_20e_iotid20_20edim_80pt.csv')\n",
    "data2 = pd.read_csv('iotid20.csv')\n",
    "\n",
    "# Assuming the last column is the target and all others are features\n",
    "data1.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "data1.dropna(inplace=True)\n",
    "\n",
    "data2.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "data2.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f845cb80-33c1-4a20-b3a3-7f453f72b650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(data1)\n",
    "\n",
    "# Phân loại các cột theo kiểu dữ liệu\n",
    "#numerical_cols = df1.select_dtypes(include=['int64', 'float64']).columns\n",
    "#categorical_cols = df1.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Tiền xử lý cột số bằng StandardScaler\n",
    "#scaler = StandardScaler()\n",
    "#df1[numerical_cols] = scaler.fit_transform(df1[numerical_cols])\n",
    "\n",
    "# Tiền xử lý cột phân loại bằng LabelEncoder\n",
    "#label_encoders = {}\n",
    "#for col in categorical_cols:\n",
    " ##   df1[col] = le.fit_transform(df1[col])\n",
    "  #  label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e4b3083-8fa8-4079-a871-fd3eec050d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Phân loại các cột theo kiểu dữ liệu\n",
    "#numerical_cols = df2.select_dtypes(include=['int64', 'float64']).columns\n",
    "#categorical_cols = df2.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Tiền xử lý cột số bằng StandardScaler\n",
    "##df2[numerical_cols] = scaler.fit_transform(df2[numerical_cols])\n",
    "\n",
    "# Tiền xử lý cột phân loại bằng LabelEncoder\n",
    "#label_encoders = {}\n",
    "#for col in categorical_cols:\n",
    "#    le = LabelEncoder()\n",
    "#    df2[col] = le.fit_transform(df2[col])\n",
    "#    label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b73da99-cab6-4ce2-9e6b-f8907c252b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "X1, y1 = df1.iloc[:, :-1], data1.iloc[:, -1]\n",
    "X2, y2 = df2.iloc[:, :-1], data2.iloc[:, -1]\n",
    "\n",
    "X1 = scaler.fit_transform(X1)\n",
    "X2 = scaler.fit_transform(X2)\n",
    "y1 = label_encoder.fit_transform(y1)\n",
    "y2 = label_encoder.fit_transform(y2)\n",
    "# Split dataset 1 into training and test sets\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split dataset 2 into training and test sets\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train MLP using the training set of the first dataset and test on the second dataset's test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de45de7e-d924-4689-be85-ed8564643935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using Dataset 1 for training and Dataset 2 for testing: 0.55\n",
      "F1 Score: 0.48\n",
      "Precision: 0.60\n",
      "Recall: 0.55\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "\n",
    "# Train on Dataset 1\n",
    "mlp.fit(X1_train, y1_train)\n",
    "\n",
    "# Test on the test set of Dataset 2\n",
    "y2_pred = mlp.predict(X2_test)\n",
    "accuracy_1 = accuracy_score(y2_test, y2_pred)\n",
    "print(f\"Accuracy using Dataset 1 for training and Dataset 2 for testing: {accuracy_1:.2f}\")\n",
    "\n",
    "# Tính toán F1 Score\n",
    "f1_1 = f1_score(y2_test, y2_pred, average='weighted')  # average='weighted' để tính trọng số cho mỗi lớp\n",
    "print(f\"F1 Score: {f1_1:.2f}\")\n",
    "\n",
    "# Tính toán Precision\n",
    "precision_1 = precision_score(y2_test, y2_pred, average='weighted')\n",
    "print(f\"Precision: {precision_1:.2f}\")\n",
    "\n",
    "# Tính toán Recall\n",
    "recall_1 = recall_score(y2_test, y2_pred, average='weighted')\n",
    "print(f\"Recall: {recall_1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "facbb629-2db1-4a59-b6aa-771aec4ac01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using the whole Dataset 2 for both training and testing: 1.00\n",
      "F1 Score: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "mlp.fit(X2_train, y2_train)\n",
    "\n",
    "y2_full_pred = mlp.predict(X2_test)\n",
    "\n",
    "# Tính toán accuracy\n",
    "accuracy_2 = accuracy_score(y2_test, y2_full_pred)\n",
    "print(f\"Accuracy using the whole Dataset 2 for both training and testing: {accuracy_2:.2f}\")\n",
    "\n",
    "# Tính toán F1 Score\n",
    "f1_2 = f1_score(y2_test, y2_full_pred, average='weighted')  # average='weighted' để tính trọng số cho mỗi lớp\n",
    "print(f\"F1 Score: {f1_2:.2f}\")\n",
    "\n",
    "# Tính toán Precision\n",
    "precision_2 = precision_score(y2_test, y2_full_pred, average='weighted')\n",
    "print(f\"Precision: {precision_2:.2f}\")\n",
    "\n",
    "# Tính toán Recall\n",
    "recall_2 = recall_score(y2_test, y2_full_pred, average='weighted')\n",
    "print(f\"Recall: {recall_2:.2f}\")\n",
    "\n",
    "\n",
    "# Compare accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83f22e91-0443-47cc-b7dd-a11623a072cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if accuracy_2 > accuracy_1:\n",
    " #   print(\"Training on the full second dataset gives better accuracy.\")\n",
    "#else:\n",
    "#    print(\"Training on the first dataset gives better accuracy on the second test set.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
