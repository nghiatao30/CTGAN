{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3325ffc8-9aff-4507-a765-1601c0f0b6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed094f0f-8b75-444e-929d-702172541ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5914ec7d-57d2-43d6-959e-34df7b9a3f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d937ffb-9099-462a-b6bb-71b48cbeae49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: wandb in c:\\users\\khang\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\khang\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in c:\\users\\khang\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (2.5.1)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\khang\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\khang\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\khang\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (5.9.7)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\khang\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in c:\\users\\khang\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (4.25.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\khang\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (4.9.0)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\khang\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\khang\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (4.1.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\khang\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: setuptools in c:\\users\\khang\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (56.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\khang\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\khang\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\khang\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\khang\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\khang\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\khang\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\khang\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\khang\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\khang\\AppData\\Local\\Programs\\Python\\Python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91212310-1202-4f91-9297-6e57fca2a951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    }
   ],
   "source": [
    "# Log in to your W&B account\n",
    "import wandb\n",
    "import psutil\n",
    "import time\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2728d9-5468-49af-bf42-26976830b285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import wandb\n",
    "\n",
    "def log_cpu_ram_usage():\n",
    "    # Đo CPU và RAM\n",
    "    cpu_percent = psutil.cpu_percent()\n",
    "    ram_percent = psutil.virtual_memory().percent\n",
    "    ram_used = psutil.virtual_memory().used / (1024 ** 3)  # Convert to GB\n",
    "\n",
    "    # Log vào WandB\n",
    "    wandb.log({\n",
    "        \"CPU_Usage (%)\": cpu_percent,\n",
    "        \"RAM_Usage (%)\": ram_percent,\n",
    "        \"RAM_Used (GB)\": ram_used\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6b96ed-6c2f-4c0c-9eba-091a771393bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetUtilizationRates, nvmlDeviceGetMemoryInfo\n",
    "\n",
    "def log_gpu_usage():\n",
    "    try:\n",
    "        nvmlInit()\n",
    "        handle = nvmlDeviceGetHandleByIndex(0)  # Assuming a single GPU\n",
    "        gpu_utilization = nvmlDeviceGetUtilizationRates(handle)\n",
    "        memory_info = nvmlDeviceGetMemoryInfo(handle)\n",
    "\n",
    "        # Log vào WandB\n",
    "        wandb.log({\n",
    "            \"GPU_Usage (%)\": gpu_utilization.gpu,\n",
    "            \"GPU_Memory_Used (GB)\": memory_info.used / (1024 ** 3),  # Convert to GB\n",
    "            \"GPU_Memory_Total (GB)\": memory_info.total / (1024 ** 3)\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error logging GPU usage: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298d946a-6489-4005-b822-661ab3259e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "data1 = pd.read_csv('ctgan_sample/ctgan_90_20e_iot20_sample.csv')\n",
    "data2 = pd.read_csv('iotid20.csv')\n",
    "\n",
    "# Assuming the last column is the target and all others are features\n",
    "data1.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "data1.dropna(inplace=True)\n",
    "\n",
    "data2.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "data2.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f845cb80-33c1-4a20-b3a3-7f453f72b650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(data1)\n",
    "\n",
    "# Phân loại các cột theo kiểu dữ liệu\n",
    "#numerical_cols = df1.select_dtypes(include=['int64', 'float64']).columns\n",
    "#categorical_cols = df1.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Tiền xử lý cột số bằng StandardScaler\n",
    "#scaler = StandardScaler()\n",
    "#df1[numerical_cols] = scaler.fit_transform(df1[numerical_cols])\n",
    "\n",
    "# Tiền xử lý cột phân loại bằng LabelEncoder\n",
    "#label_encoders = {}\n",
    "#for col in categorical_cols:\n",
    " ##   df1[col] = le.fit_transform(df1[col])\n",
    "  #  label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4b3083-8fa8-4079-a871-fd3eec050d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Phân loại các cột theo kiểu dữ liệu\n",
    "#numerical_cols = df2.select_dtypes(include=['int64', 'float64']).columns\n",
    "#categorical_cols = df2.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Tiền xử lý cột số bằng StandardScaler\n",
    "##df2[numerical_cols] = scaler.fit_transform(df2[numerical_cols])\n",
    "\n",
    "# Tiền xử lý cột phân loại bằng LabelEncoder\n",
    "#label_encoders = {}\n",
    "#for col in categorical_cols:\n",
    "#    le = LabelEncoder()\n",
    "#    df2[col] = le.fit_transform(df2[col])\n",
    "#    label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b73da99-cab6-4ce2-9e6b-f8907c252b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "X1, y1 = df1.iloc[:, :-1], data1.iloc[:, -1]\n",
    "X2, y2 = df2.iloc[:, :-1], data2.iloc[:, -1]\n",
    "\n",
    "X1 = scaler.fit_transform(X1)\n",
    "X2 = scaler.fit_transform(X2)\n",
    "y1 = label_encoder.fit_transform(y1)\n",
    "y2 = label_encoder.fit_transform(y2)\n",
    "# Split dataset 1 into training and test sets\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split dataset 2 into training and test sets\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train MLP using the training set of the first dataset and test on the second dataset's test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de45de7e-d924-4689-be85-ed8564643935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using Dataset 1 for training and Dataset 2 for testing: 0.74\n",
      "F1 Score: 0.72\n",
      "Precision: 0.73\n",
      "Recall: 0.74\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "\n",
    "# Train on Dataset 1\n",
    "mlp.fit(X1_train, y1_train)\n",
    "wandb.init(\n",
    "    project=\"ct_dim_usage\"\n",
    "    config={\n",
    "        \"model\": \"MLPClassifier\",\n",
    "        \"hidden_layers\": (100,),\n",
    "        \"max_iter\": 500,\n",
    "        \"dataset\": \"IoTID20\",\n",
    "        \"random_state\": 42\n",
    "    }\n",
    ")\n",
    "log_cpu_ram_usage()\n",
    "log_gpu_usage()\n",
    "\n",
    "# Test on the test set of Dataset 2\n",
    "y2_pred = mlp.predict(X2_test)\n",
    "accuracy_1 = accuracy_score(y2_test, y2_pred)\n",
    "print(f\"Accuracy using Dataset 1 for training and Dataset 2 for testing: {accuracy_1:.2f}\")\n",
    "\n",
    "# Tính toán F1 Score\n",
    "f1_1 = f1_score(y2_test, y2_pred, average='weighted')  # average='weighted' để tính trọng số cho mỗi lớp\n",
    "print(f\"F1 Score: {f1_1:.2f}\")\n",
    "\n",
    "# Tính toán Precision\n",
    "precision_1 = precision_score(y2_test, y2_pred, average='weighted')\n",
    "print(f\"Precision: {precision_1:.2f}\")\n",
    "\n",
    "# Tính toán Recall\n",
    "recall_1 = recall_score(y2_test, y2_pred, average='weighted')\n",
    "print(f\"Recall: {recall_1:.2f}\")\n",
    "\n",
    "wandb.log({\n",
    "    \"Accuracy\": accuracy_1,\n",
    "    \"F1_Score\": f1_1,\n",
    "    \"Precision\": precision_1,\n",
    "    \"Recall\": recall_1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facbb629-2db1-4a59-b6aa-771aec4ac01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Dự đoán trên toàn bộ Dataset 2 (test set)\n",
    "#y2_full_pred = mlp.predict(X2_test)\n",
    "\n",
    "# Tính toán accuracy\n",
    "#accuracy_2 = accuracy_score(y2_test, y2_full_pred)\n",
    "#print(f\"Accuracy using the whole Dataset 2 for both training and testing: {accuracy_2:.2f}\")\n",
    "\n",
    "# Tính toán F1 Score\n",
    "#f1_2 = f1_score(y2_test, y2_full_pred, average='weighted')  # average='weighted' để tính trọng số cho mỗi lớp\n",
    "#print(f\"F1 Score: {f1_2:.2f}\")\n",
    "\n",
    "# Tính toán Precision\n",
    "#precision_2 = precision_score(y2_test, y2_full_pred, average='weighted')\n",
    "#print(f\"Precision: {precision_2:.2f}\")\n",
    "\n",
    "# Tính toán Recall\n",
    "#recall_2 = recall_score(y2_test, y2_full_pred, average='weighted')\n",
    "#print(f\"Recall: {recall_2:.2f}\")\n",
    "\n",
    "\n",
    "# Compare accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f22e91-0443-47cc-b7dd-a11623a072cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if accuracy_2 > accuracy_1:\n",
    " #   print(\"Training on the full second dataset gives better accuracy.\")\n",
    "#else:\n",
    "#    print(\"Training on the first dataset gives better accuracy on the second test set.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
